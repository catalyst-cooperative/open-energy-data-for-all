{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading remote data into `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example: reading parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_parquet in module pandas.io.parquet:\n",
      "\n",
      "read_parquet(path: 'FilePath | ReadBuffer[bytes]', engine: 'str' = 'auto', columns: 'list[str] | None' = None, storage_options: 'StorageOptions | None' = None, use_nullable_dtypes: 'bool | lib.NoDefault' = <no_default>, dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>, filesystem: 'Any' = None, filters: 'list[tuple] | list[list[tuple]] | None' = None, **kwargs) -> 'DataFrame'\n",
      "    Load a parquet object from the file path, returning a DataFrame.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    path : str, path object or file-like object\n",
      "        String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      "        object implementing a binary ``read()`` function.\n",
      "        The string could be a URL. Valid URL schemes include http, ftp, s3,\n",
      "        gs, and file. For file URLs, a host is expected. A local file could be:\n",
      "        ``file://localhost/path/to/table.parquet``.\n",
      "        A file URL can also be a path to a directory that contains multiple\n",
      "        partitioned parquet files. Both pyarrow and fastparquet support\n",
      "        paths to directories as well as file URLs. A directory path could be:\n",
      "        ``file://localhost/path/to/tables`` or ``s3://bucket/partition_dir``.\n",
      "    engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      "        Parquet library to use. If 'auto', then the option\n",
      "        ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      "        behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      "        'pyarrow' is unavailable.\n",
      "\n",
      "        When using the ``'pyarrow'`` engine and no storage options are provided\n",
      "        and a filesystem is implemented by both ``pyarrow.fs`` and ``fsspec``\n",
      "        (e.g. \"s3://\"), then the ``pyarrow.fs`` filesystem is attempted first.\n",
      "        Use the filesystem keyword with an instantiated fsspec filesystem\n",
      "        if you wish to use its implementation.\n",
      "    columns : list, default=None\n",
      "        If not None, only these columns will be read from the file.\n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "        .. versionadded:: 1.3.0\n",
      "\n",
      "    use_nullable_dtypes : bool, default False\n",
      "        If True, use dtypes that use ``pd.NA`` as missing value indicator\n",
      "        for the resulting DataFrame. (only applicable for the ``pyarrow``\n",
      "        engine)\n",
      "        As new dtypes are added that support ``pd.NA`` in the future, the\n",
      "        output with this option will change to use those dtypes.\n",
      "        Note: this is an experimental option, and behaviour (e.g. additional\n",
      "        support dtypes) may change without notice.\n",
      "\n",
      "        .. deprecated:: 2.0\n",
      "\n",
      "    dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "        Back-end data type applied to the resultant :class:`DataFrame`\n",
      "        (still experimental). Behaviour is as follows:\n",
      "\n",
      "        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "          (default).\n",
      "        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "          DataFrame.\n",
      "\n",
      "        .. versionadded:: 2.0\n",
      "\n",
      "    filesystem : fsspec or pyarrow filesystem, default None\n",
      "        Filesystem object to use when reading the parquet file. Only implemented\n",
      "        for ``engine=\"pyarrow\"``.\n",
      "\n",
      "        .. versionadded:: 2.1.0\n",
      "\n",
      "    filters : List[Tuple] or List[List[Tuple]], default None\n",
      "        To filter out data.\n",
      "        Filter syntax: [[(column, op, val), ...],...]\n",
      "        where op is [==, =, >, >=, <, <=, !=, in, not in]\n",
      "        The innermost tuples are transposed into a set of filters applied\n",
      "        through an `AND` operation.\n",
      "        The outer list combines these sets of filters through an `OR`\n",
      "        operation.\n",
      "        A single list of tuples can also be used, meaning that no `OR`\n",
      "        operation between set of filters is to be conducted.\n",
      "\n",
      "        Using this argument will NOT result in row-wise filtering of the final\n",
      "        partitions unless ``engine=\"pyarrow\"`` is also specified.  For\n",
      "        other engines, filtering is only performed at the partition level, that is,\n",
      "        to prevent the loading of some row-groups and/or files.\n",
      "\n",
      "        .. versionadded:: 2.1.0\n",
      "\n",
      "    **kwargs\n",
      "        Any additional kwargs are passed to the engine.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_parquet : Create a parquet object that serializes a DataFrame.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> original_df = pd.DataFrame(\n",
      "    ...     {\"foo\": range(5), \"bar\": range(5, 10)}\n",
      "    ...    )\n",
      "    >>> original_df\n",
      "       foo  bar\n",
      "    0    0    5\n",
      "    1    1    6\n",
      "    2    2    7\n",
      "    3    3    8\n",
      "    4    4    9\n",
      "    >>> df_parquet_bytes = original_df.to_parquet()\n",
      "    >>> from io import BytesIO\n",
      "    >>> restored_df = pd.read_parquet(BytesIO(df_parquet_bytes))\n",
      "    >>> restored_df\n",
      "       foo  bar\n",
      "    0    0    5\n",
      "    1    1    6\n",
      "    2    2    7\n",
      "    3    3    8\n",
      "    4    4    9\n",
      "    >>> restored_df.equals(original_df)\n",
      "    True\n",
      "    >>> restored_bar = pd.read_parquet(BytesIO(df_parquet_bytes), columns=[\"bar\"])\n",
      "    >>> restored_bar\n",
      "        bar\n",
      "    0    5\n",
      "    1    6\n",
      "    2    7\n",
      "    3    8\n",
      "    4    9\n",
      "    >>> restored_bar.equals(original_df[['bar']])\n",
      "    True\n",
      "\n",
      "    The function uses `kwargs` that are passed directly to the engine.\n",
      "    In the following example, we use the `filters` argument of the pyarrow\n",
      "    engine to filter the rows of the DataFrame.\n",
      "\n",
      "    Since `pyarrow` is the default engine, we can omit the `engine` argument.\n",
      "    Note that the `filters` argument is implemented by the `pyarrow` engine,\n",
      "    which can benefit from multithreading and also potentially be more\n",
      "    economical in terms of memory.\n",
      "\n",
      "    >>> sel = [(\"foo\", \">\", 2)]\n",
      "    >>> restored_part = pd.read_parquet(BytesIO(df_parquet_bytes), filters=sel)\n",
      "    >>> restored_part\n",
      "        foo  bar\n",
      "    0    3    8\n",
      "    1    4    9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"https://s3.us-west-2.amazonaws.com/pudl.catalyst.coop/nightly/core_eia923__monthly_generation_fuel.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 11, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.report_date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapt your previous Excel-reading code to read the same Excel file directly from the Internet. GitHub has convenient links for all the files in the repo - you should be able to find the Excel file here: `https://github.com/catalyst-cooperative/open-energy-data-for-all/raw/refs/heads/main/data/eia923_2022.xlsx`\n",
    "\n",
    "Start with the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# modify this to read from the URL!\n",
    "pd.read_excel(\"data/eia923_2022.xlsx\", skiprows=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### key point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most, but not all, of the `read_*` functions support URLs -  check the docs to make sure this will work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "What are some advantages and disadvantages you can imagine for using remote data vs. saving the data to your hard drive (aka **local data**)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `requests` to download files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example: EIA 923 JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://raw.githubusercontent.com/catalyst-cooperative/open-energy-data-for-all/refs/heads/main/data/eia923_2022.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapt the JSON reading code from last episode to use requests.get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open('data/eia923_2022.json') as file:\n",
    "    eia923_json = json.load(file)\n",
    "\n",
    "eia923_json_df = pd.DataFrame(eia923_json[\"response\"][\"data\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### key points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `requests` is useful when you need to reformat the data before shoving it into `pandas`\n",
    "* `response.status_code` tells you if the request succeeded or why it failed.\n",
    "* `response.text` gives you the raw response, if you need to check that the data is formatted how you expect\n",
    "* `response.json()` will parse the response as JSON, which is handy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web APIs: Fancy URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://api.eia.gov/v2/electricity/electric-power-operational-data/data?data[]=consumption-for-eg&facets[fueltypeid][]=NG&facets[sectorid][]=99&facets[location][]=CO&frequency=annual&start=2020&end=2023&api_key=3zjKYxV86AqtJWSRoAECir1wQFscVu6lxXnRVKG8\")\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api.eia.gov/v2/electricity/electric-power-operational-data/data?\n",
    "# data[]=consumption-for-eg&\n",
    "# facets[fueltypeid][]=NG&\n",
    "# facets[sectorid][]=99&facets[location][]=CO&frequency=annual&start=2020&end=2023&api_key=3zjKYxV86AqtJWSRoAECir1wQFscVu6lxXnRVKG8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a request to `https://api.eia.gov/v2/electricity/electric-power-operational-data/data?data[]=consumption-for-eg&facets[fueltypeid][]=NG&facets[sectorid][]=99&facets[location][]=CO&frequency=annual&start=2020&end=2023&api_key=3zjKYxV86AqtJWSRoAECir1wQFscVu6lxXnRVKG8` with `requests.get`.\n",
    "\n",
    "Try removing the `end=2023` parameter from the URL. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### key points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* web APIs can be thought of as bundles of fancy URLs\n",
    "* each web API is different, but if you can read the documentation and make requests to URLs, you can figure them out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study: EIA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"3zjKYxV86AqtJWSRoAECir1wQFscVu6lxXnRVKG8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're looking for yearly data about fuel consumption at the plant level, what route should we request next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.eia.gov/v2/electricity\"\n",
    "\n",
    "# requests.get(\"some route for the fuel consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example: drilling down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above example, and the output for the `facility-fuels` metadata, how do we get the net generation data?\n",
    "\n",
    "Build off of the earlier request, reproduced below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what should the url be changed to?\n",
    "facility_fuel = requests.get(f\"{base_url}/facility-fuel?api_key={api_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example: frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly = requests.get(f\"{base_url}/facility-fuel/data?data[]=generation&frequency=yearly&api_key={api_key}\")\n",
    "yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual = requests.get(f\"{base_url}/facility-fuel/data?data[]=generation&frequency=annual&api_key={api_key}\")\n",
    "\n",
    "annual.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual = requests.get(\n",
    "    f\"{base_url}/facility-fuel/data\",\n",
    "    params={\n",
    "        \"data[]\": \"generation\",\n",
    "        \"frequency\": \"annual\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    ")\n",
    "\n",
    "annual.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### example: \"faceting\" / filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_fuel.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fueltypes = requests.get(f\"{base_url}/facility-fuel/facet/fuel2002?api_key={api_key}\").json()\n",
    "\n",
    "fueltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_ng = requests.get(\n",
    "    f\"{base_url}/facility-fuel/data\",\n",
    "    params={\n",
    "        \"data[]\": \"generation\",\n",
    "        \"frequency\": \"annual\",\n",
    "        \"facets[fuel2002][]\": \"NG\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    ")\n",
    "\n",
    "annual_ng.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to limit this to just the state of Colorado - let's update the code to do that.\n",
    "\n",
    "As before, let's build off the old request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_ng = requests.get(\n",
    "    f\"{base_url}/facility-fuel/data\",\n",
    "    params={\n",
    "        \"data[]\": \"generation\",\n",
    "        \"frequency\": \"annual\",\n",
    "        \"facets[fuel2002][]\": \"NG\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    ")\n",
    "\n",
    "annual_ng.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example: time limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw the start/end parameters a bit earlier, but let's actually poke at the documentation to see how they're used:\n",
    "\n",
    "![Screenshot with several examples, reproduced below](../episodes/fig/ep-3/start-end.png)\n",
    "\n",
    "> Start date\n",
    "> https://api.eia.gov/v2/electricity/retail-sales/data?api_key=xxxxxx&data[]=price&facets[sectorid][]=RES&facets[stateid][]=CO&frequency=monthly&start=2008-01-31\n",
    ">\n",
    "> End date\n",
    "> https://api.eia.gov/v2/electricity/retail-sales/data?api_key=xxxxxx&data[]=price&facets[sectorid][]=RES&facets[stateid][]=CO&frequency=monthly&end=2008-03-01\n",
    ">\n",
    "> Start and end date together\n",
    "> https://api.eia.gov/v2/electricity/retail-sales/data?api_key=xxxxxx&data[]=price&facets[sectorid][]=RES&facets[stateid][]=CO&frequency=monthly&start=2008-01-31&end=2008-03-01\n",
    "\n",
    "Let's try out this pattern!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit the results to 2020-2023. Start from your last query, reproduced below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_ng_co = requests.get(\n",
    "    f\"{base_url}/facility-fuel/data\",\n",
    "    params={\n",
    "        \"data[]\": \"generation\",\n",
    "        \"frequency\": \"annual\",\n",
    "        \"facets[fuel2002][]\": \"NG\",\n",
    "        \"facets[state][]\": \"CO\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    ")\n",
    "\n",
    "annual_ng_co.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think back to the metadata you saw - what are some questions can you answer with the `facility-fuel` endpoint?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many functions in the `pandas.read_*` family can read tabular data from remote servers & cloud storage as if it was on your local computer\n",
    "* `requests` can get data that's not in the right shape for `pandas.read_*`; you'll have to do the translation from their response format into `pandas.DataFrame` yourself\n",
    "* web APIs are just collections of fancy URLs, which you can interact with via `requests`\n",
    "* to learn an API, you need to be able to read the documentation and experiment with the API to see how it responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
